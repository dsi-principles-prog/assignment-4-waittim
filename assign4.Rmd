---
title: "assign4"
output: html_notebook
---


For the regular expression exercises, try writing first using regular expressions directly, then try using rverbalexpressions. Provide the code for both. 

```{r libraries}
library(lubridate)
library(stringr)
library(RVerbalExpressions)
```


# Part 1

## R4DS 16.4.5

**Create a vector of dates giving the first day of every month in the current year. **
```{r generate year}
ymd_v <- ymd(str_c(year(now()), ",", seq(1, 12, 1), ",01"))
ymd_v
```


**Write a function that given your birthday (as a date), returns how old you are in years.**

```{r calculate age}
count_age <- function(x){
  age <- year(now())-year(ymd(x))
  age
}
count_age(19960406)
```


**Write a function that given your birthday, returns the day of the week you were born on. **

```{r calculate weekday}
call_week <- function(x){
  weekday <- wday(ymd(x),label = T)
  weekday
}
call_week(19960406)
```


## R4DS 14.3.2.1

**Given the corpus of common words in stringr::words, create regular expressions that find all words that have seven letters or more. (Since this list is long, you might want to use the match argument to str_view() to show only the matching or non-matching words.)**

```{r import data, include=FALSE}
stringr::words
```

```{r more than 7}
str_view(words, "\\w{7,}", match = TRUE)

morethan7 <- rx() %>%
  rx_word_char() %>%
  rx_repeat_previous(7) %>%
  rx_anything()
morethan7

str_view(words, morethan7, match = TRUE)

```


## R4DS 14.3.3.1

**Use str_detect to find all words that:**

**That only contain consonants. (Hint: thinking about matching “not”-vowels.)**

```{r only consonants}
words[str_detect(words, "^[^aeiou]+$") ]

consonants_only <- rx() %>%
  rx_start_of_line() %>%
  rx_something_but("aeiou") %>%
  rx_end_of_line()
consonants_only

words[str_detect(words, consonants_only) ]

```

**Empirically verify the rule “i before e except after c”.**

```{r no c before ie}
words[str_detect(words, "cie")]

nc_ie <- rx() %>%
  rx_find("cie")
nc_ie

words[str_detect(words, nc_ie)]

```
not corect

**Create a regular expression that will match telephone numbers as commonly written in the US. Split this up into multiple expressions as needed.**

```{r telephone number}

telen <- rx() %>%
  rx_start_of_line() %>%
  rx_maybe("(") %>%
  rx_digit() %>%
  rx_repeat_previous(3) %>%
  rx_maybe(")") %>%
  rx_any_of(" .-") %>%
  rx_digit() %>%
  rx_repeat_previous(3) %>%
  rx_any_of(" .-") %>%
  rx_digit() %>%
  rx_repeat_previous(4) %>%
  rx_end_of_line() 
telen

phonenum <- c("(615) 972-0128","(615) 481.3147","66z.777 8888")

phonenum[str_detect(phonenum, "^(\\()?[0-9]{3}(\\))?[ -\\.][0-9]{3}[ -\\.][0-9]{4}$")]

phonenum[str_detect(phonenum, telen)]

```




# Part 2


Choose a dataset (this can be the same dataset as the last assignment, or a new one). Define a predictive modeling problem. Create the appropriate files and notebooks to do the following:


## YouToBe Video Trending Prediction

### Describe the data and the problem

This dataset comes from Kaggle Competitions, includes several months (and counting) of data on daily trending YouTube videos. Data is for the US with up to 200 listed trending videos per day.

Data includes the video title, channel title, publish time, tags, views, likes and dislikes, description, and comment count, etc. 

We can use this dataset to predict the video will be popular or not in the future when the youtuber just publishes it.

Library list: 
(The packages will be used in this part, except the packages inside the feature engineering functions.)

```{r libraries_list, include=FALSE}
library(readr)
library(janitor)
library(assertr)
library(tidyverse)
library(lubridate)
library(glue)
```


### Read in and check data

Now we can import the dataset and clean the names first.

```{r import part2 data, include=FALSE}
USvideos <- read_csv("USvideos.csv") %>%
  clean_names()
```

For the operation in the future, having a overview can help us understand the dataset easily.

```{r overview}
dim(USvideos)
str(USvideos)
```

Now we need to make sure is there any outlier or mistake in the dataset.

First, test the column called "category_id". There are 43 categories, therefore the values in the column should not be bigger than 43 or smaller than 1.

```{r assert category}
assert(data = USvideos, in_set(1, 43, allow.na = FALSE), category_id) 
```

There are 5 rows have NA in this column, we can just remove them later.

For the numerical columns in the dataset, based on the reality, all of them should be positive.

```{r assert positive number}
assert(data = USvideos, within_bounds(lower.bound = 0, upper.bound = Inf, allow.na = FALSE), views)
assert(data = USvideos, within_bounds(lower.bound = 0,upper.bound = Inf, allow.na = FALSE), likes)
assert(data = USvideos, within_bounds(lower.bound = 0, upper.bound = Inf, allow.na = FALSE), dislikes)
assert(data = USvideos, within_bounds(lower.bound = 0, upper.bound = Inf, allow.na = FALSE), comment_count)
```

Fortunately, all of the numbers are positive. There is no mistake.

And for the logical columns, all of the values should be TRUE or FALSE.

```{r assert logical}
assert(data = USvideos, in_set(TRUE, FALSE, allow.na = FALSE), comments_disabled)
assert(data = USvideos, in_set(TRUE, FALSE, allow.na = FALSE), ratings_disabled)
assert(data = USvideos, in_set(TRUE, FALSE, allow.na = FALSE), video_error_or_removed) 
```

And there is no error too.


### Clean up the data. 

Because there are only several observations with NA values, we can just remove all of the rows which have NA value.
```{r remove NA}
USvideos_NNA <- as.data.frame(na.omit(USvideos))
USvideos_NNA
```

Then we need to convert the column called "trending_date" with character type to normal date format in "lubridate" package.

```{r comvert to lubridate}
USvideos_NNA <- USvideos_NNA %>%
  mutate(trending_date = ydm(trending_date))
```

Now let's look through the structure of dataset again.

```{r overview2}
str(USvideos_NNA)
```



*Note: You may request that score for these sections replace your score for the coding portion of Assignment 3.*

### Using best practices, write four functions which add engineered features to the dataset, including a description and rationale. Include a test to determine whether the features are working as intended. 

Create a function for spliting the trending date column into 3 columns. And in this part, we can verify the column type first to make sure it's date type or not. If it isn't a date type column, the function will stop and reture "Not a date format, please use 'lubridate' package."

```{r get_day_point}
get_day_point <- function(df, day_column){
  library(lubridate)
  library(tidyverse)

  if(class(df[[day_column]])=="Date"){
    print("Date format check done.")
  }else{
      stop("Not a date format, please use 'lubridate' package.")
  }

  df %>%
    mutate_at(day_column, list(date_year=year, 
                               date_month=month, 
                               date_day=day)) 
}
```

Test the function.
```{r get_day_point test}
get_day_point(USvideos_NNA, "trending_date")%>%
  select(date_year,date_month,date_day)
```

And for the column called "publish_time", we can split it into 6 columns. The type is "POSIXct", what is different with the last one. And this function will test the type first too.
```{r get_time_point}
get_time_point <- function(df, time_column){
  library(lubridate)
  library(tidyverse)

  if(class(df[[time_column]])[1]=="POSIXct"){
    print("Timeformat check done.")
  }else{
      stop("Not a time format, please use 'lubridate' package.")
  }
  df %>%
    mutate_at(time_column, list(time_year=year, 
                                time_month=month, 
                                time_day=day, 
                                time_hour=hour, 
                                time_minute=minute, 
                                time_second=second)) 
}
```

Test the function.
```{r get_time_point test}
get_time_point(USvideos_NNA, "publish_time") %>%
select(time_year,time_month,time_day,time_hour,time_minute,time_second)
```

Now we will create a function to count the number of rows in decription column. The pattern of Line break symbol is "\\n". Count the number of "\\n" and plus 1, the result should be the the number of row.
```{r count_rows}
count_rows <- function(df, chr_column){
  library(tidyverse)
  df %>%
    mutate(chr_row_num = stringr::str_count({{chr_column}}, pattern = fixed("\\n")) + 1)
}
```

Test the function.
```{r count_rows test}
count_rows(USvideos_NNA, description) %>%
  select(description,chr_row_num)
```

This function is similar to the last one but it is used to count the number of tags. And the dataset use "|" to split the tags. So the number of tags should be the number of "|" plus 1.
```{r count_pattern}
count_pattern <- function(df, tag_column){
  library(tidyverse)
  df %>%
    mutate(pattern_num = stringr::str_count({{tag_column}}, pattern = fixed('"|"')) + 1)
}
```

Test the function.
```{r count_pattern test}
count_pattern(USvideos_NNA, tags) %>%
  select(tags,pattern_num)
```

The length of title might influence the result too. Therefore we could create a funcion to calculate the length of character column.
Of course, this function could be used to calculate the length of description column too.
```{r get_chr_length}
get_chr_length <- function(df, chr_column){
  library(tidyverse)
  df %>%
    mutate(chr_length = stringr::str_length({{chr_column}}))
}
```

Test the function.
```{r get_chr_length test}
get_chr_length(USvideos_NNA, title) %>%
  select(title,chr_length)
```

Sometimes we might need calculate the ratio between 2 variables. This function can help us to get the ratio column.
```{r get_ratio}
get_ratio <- function(df, numerator, denominator){
  if(class(df[[numerator]]) == "double" & class(df[[denominator]]) == "double"){
    print("numerical format check done.")
  }else{
    stop("Not a numerical format.")
  }
  df %>%
    mutate(new_col_name = {{numerator}}/{{denominator}})
}
```

Because there are some logical columns in our dataset, but if we want to use machine learning to predict the trending video, it will be easier when we convert them from TRUE/FALSE into 1/0.
```{r convert_to_01}
convert_to_01 <- function(df, comments_disabled_logi, ratings_disabled_logi, video_error_removed_logi){
  df %>% 
    mutate( comments_disabled = case_when({{comments_disabled_logi}}==TRUE ~ 1,
                                          {{comments_disabled_logi}}==FALSE ~ 0)) %>%
    mutate( ratings_disabled = case_when({{ratings_disabled_logi}}==TRUE ~ 1,
                                         {{ratings_disabled_logi}}==FALSE ~ 0)) %>%
    mutate( video_error_or_removed = case_when({{video_error_removed_logi}}==TRUE ~ 1,
                                               {{video_error_removed_logi}}==FALSE ~ 0)) 
}
```

Test the function.
```{r convert_to_01 test}
convert_to_01(USvideos_NNA, comments_disabled, ratings_disabled, video_error_or_removed) %>%
  select(comments_disabled,ratings_disabled,video_error_or_removed)
```


### Prepare the data for modeling

Now use the functions we defined before to complish the feature engineering.
```{r feature engineering}
USvideos_NNA <- get_day_point(USvideos_NNA, "trending_date")

USvideos_NNA <- get_time_point(USvideos_NNA, "publish_time")

USvideos_NNA <- count_rows(USvideos_NNA, description)

USvideos_NNA <- count_pattern(USvideos_NNA, tags)

USvideos_NNA <- get_chr_length(USvideos_NNA, title)

USvideos_NNA <- convert_to_01(USvideos_NNA, comments_disabled, ratings_disabled, video_error_or_removed)
```

A quick overview after the feature engineering result.
```{r overview after fe}
head(USvideos_NNA)
```

Now we can just select all of the numerical columns for modeling conveniently. Based on the data, we can try to use a simple machine learning model to predict.
The columns called "views", "likes", "dislikes" and "comment_count" might can be used to identify the video is trending or not as the label. And the others could be used as inputs.
```{r select useful column}
USvideos_ML <- USvideos_NNA %>%
  select(views, 
         likes, 
         dislikes, 
         comment_count, 
         category_id, 
         comments_disabled, 
         ratings_disabled, 
         video_error_or_removed,
         date_year,
         date_month,
         date_day,
         time_year,
         time_month,
         time_day,
         time_hour,
         time_minute,
         time_second,
         chr_row_num,
         pattern_num,
         chr_length)
USvideos_ML
```

Note: remember divide the samples to trainning set and test set randomly first.

